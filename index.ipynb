{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Scraping Concerts - Lab\n", "\n", "## Introduction\n", "\n", "Now that you've seen how to scrape a simple website, it's time to again practice those skills on a full-fledged site!\n", "\n", "In this lab, you'll practice your scraping skills on an online music magazine and events website called Resident Advisor.\n", "\n", "## Objectives\n", "\n", "You will be able to:\n", "\n", "* Create a full scraping pipeline that involves traversing over many pages of a website, dealing with errors and storing data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## View the Website\n", "\n", "For this lab, you'll be scraping the https://ra.co website. For reproducibility we will use the [Internet Archive](https://archive.org/) Wayback Machine to retrieve a version of this page from March 2019.\n", "\n", "Start by navigating to the events page [here](https://web.archive.org/web/20210325230938/https://ra.co/events/us/newyork?week=2019-03-30) in your browser. It should look something like this:\n", "\n", "<img src=\"images/ra_top.png\">"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Open the Inspect Element Feature\n", "\n", "Next, open the inspect element feature from your web browser in order to preview the underlying HTML associated with the page."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Write a Function to Scrape all of the Events on the Given Page\n", "\n", "The function should return a Pandas DataFrame with columns for the `Event_Name`, `Venue`, and `Number_of_Attendees`.\n", "\n", "Start by importing the relevant libraries, making a request to the relevant URL, and exploring the contents of the response with `BeautifulSoup`. Then fill in the `scrape_events` function with the relevant code."]}, {"cell_type": "code", "execution_count": 26, "metadata": {}, "outputs": [], "source": ["# Relevant imports\n", "import requests\n", "from bs4 import BeautifulSoup\n", "import numpy as np\n", "import pandas as pd\n", "import time"]}, {"cell_type": "code", "execution_count": 27, "metadata": {}, "outputs": [], "source": ["\n", "EVENTS_PAGE_URL = \"https://web.archive.org/web/20210326225933/https://ra.co/events/us/newyork?week=2019-03-30\"\n", "\n", "# Exploration: making the request and parsing the response\n", "response = requests.get(EVENTS_PAGE_URL)\n", "soup = BeautifulSoup(response.content, \"html.parser\")"]}, {"cell_type": "code", "execution_count": 28, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u0338Sat, 30 MarUnterMania IIMary Yuzovskaya, Manni Dee, Umfang, Juana, The Lady MachineTBA - New YorkRARA Tickets457Cocoon New York: Sven V\u00e4th, Ilario Alicante, Butch & TaimurSven Vath, Butch, Taimur, Il\n", "\n", "Sun, 31 MarSunday: Soul SummitNowadaysRARA Tickets132New Dad & Aaron Clark (Honcho)Aaron Clark, New DadAce Hotel3ParadiscoOccupy The DiscoLe Bain3Sunday Soiree: Unknown Showcase (Detroit)Ryan Dahl, Ha\n"]}], "source": ["\n", "# Find the container with event listings in it\n", "\n", "# This page is organized somewhat unusually, and many of\n", "# the CSS attributes seem auto-generated. We notice that\n", "# there is a div with \"events-all\" in its attributes that\n", "# looks promising\n", "events_all_div = soup.find('div', attrs={\"data-tracking-id\": \"events-all\"})\n", "\n", "# The actual content is nested in a ul containing a single\n", "# li within that div. Unclear why they are using a \"list\"\n", "# concept for one element, but let's go ahead and select it\n", "event_listings = events_all_div.find(\"ul\").find(\"li\")\n", "\n", "# Print out some chunks of the text inside to make sure we\n", "# have everything we need in here\n", "\n", "# Beginning has events for March 30th\n", "print(event_listings.text[:200])\n", "print()\n", "# Later we have events for March 31st\n", "march_31st_start = event_listings.text.find(\"Sun, 31 Mar\")\n", "print(event_listings.text[march_31st_start:march_31st_start + 200])\n", "\n", "# It looks like everything we need will be inside this event_listings tag"]}, {"cell_type": "code", "execution_count": 29, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["0 index: \u0338Sat, 30 MarUnterMania IIMary Yuzovskaya, Manni Dee, Umfang, Juana, The Lady MachineTBA - New YorkRARA Tickets457Cocoon New York: Sven V\u00e4th, Ilario Alicante, Butch & TaimurSven Vath, Butch, Taimur, Il\n", "\n", "1 index:  \n", "\n", "2 index: \u0338Sun, 31 MarSunday: Soul SummitNowadaysRARA Tickets132New Dad & Aaron Clark (Honcho)Aaron Clark, New DadAce Hotel3ParadiscoOccupy The DiscoLe Bain3Sunday Soiree: Unknown Showcase (Detroit)Ryan Dahl, H\n"]}], "source": ["\n", "# Find a list of events by date within that container\n", "\n", "# Now we look at what is inside of that event_listings li tag.\n", "# Based on looking at the HTML with developer tools, we see\n", "# that there are 13 children of that tag, all divs. Each div\n", "# is either a container of events on a given date, or empty\n", "\n", "# Let's create a collection of those divs. recursive=False\n", "# means we stop at 1 level below the event_listings li\n", "dates = event_listings.findChildren(recursive=False)\n", "\n", "# Now let's print out the start of the March 30th and March\n", "# 31st sections again. This time each is in its own \"date\"\n", "# container\n", "\n", "# March 30th is at the 0 index\n", "print(\"0 index:\", dates[0].text[:200])\n", "print()\n", "# The 1 index is empty. We'll need to skip this later\n", "print(\"1 index: \", dates[1].text)\n", "print()\n", "# March 31st is at the 2 index\n", "print(\"2 index:\", dates[2].text[:200])\n", "\n", "# Now we know we can loop over all of the items in the dates\n", "# list of divs to find the dates, although some will be blank\n", "# so we'll need to skip them"]}, {"cell_type": "code", "execution_count": 30, "metadata": {}, "outputs": [{"data": {"text/plain": ["'Sat, 30 Mar'"]}, "execution_count": 30, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# Extract the date (e.g. Sat, 30 Mar) from one of those containers\n", "\n", "# Grabbing just one to practice on\n", "first_date = dates[0]\n", "\n", "# This div contains a div with the date, followed by several uls\n", "# containing actual event information\n", "\n", "# The div with the date happens to have another human-readable\n", "# CSS class, so let's use that to select it then grab its text\n", "date = first_date.find(\"div\", class_=\"sticky-header\").text\n", "\n", "# There is a / thing used for aesthetic reasons; let's remove it\n", "date = date.strip(\"'\u0338\")\n", "date"]}, {"cell_type": "code", "execution_count": 31, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Name: UnterMania II\n", "Venue: TBA - New York\n", "Date: Sat, 30 Mar\n", "Number of attendees: 457\n"]}], "source": ["\n", "# Extract the name, venue, and number of attendees from one of the\n", "# events within that container\n", "\n", "# As noted previously, the div with information about events on\n", "# this date contains several ul tags, each with information about\n", "# a specific event. Get a list of them.\n", "# (Again this is an odd use of HTML, to have an unordered list\n", "# containing a single list item. But we scrape what we find!)\n", "first_date_events = first_date.findChildren(\"ul\")\n", "\n", "# Grabbing the first event ul to practice on\n", "first_event = first_date_events[0]\n", "\n", "# Each event ul contains a single h3 with the event name, easy enough\n", "name = first_event.find(\"h3\").text\n", "\n", "# Venue and attendees is more complicated. Across the bottom are 1-3\n", "# divs with height 30. The 0th contains a location pin SVG and then\n", "# the location text. The -1th (last), when present, contains a person\n", "# icon SVG and then the number of attendees. Sometimes there is a\n", "# middle div with a ticket icon SVG and the words \"RA Tickets\", which\n", "# we will plan to ignore\n", "\n", "# First, get all 1-3 divs that match this description\n", "venue_and_attendees = first_event.findAll(\"div\", attrs={\"height\": 30})\n", "# The venue is the 0th (left-most) div, get its text\n", "venue = venue_and_attendees[0].text\n", "# The number of attendees is the last div (although it's sometimes\n", "# missing), get its text\n", "num_attendees = int(venue_and_attendees[-1].text)\n", "\n", "# Print out everything for one event\n", "print(\"Name:\", name)\n", "print(\"Venue:\", venue)\n", "print(\"Date:\", date)\n", "print(\"Number of attendees:\", num_attendees)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "# Testing that code out on an event with a missing attendee count\n", "# N.B. This will crash\n", "last_event = first_date_events[-1]\n", "\n", "name = last_event.find(\"h3\").text\n", "\n", "venue_and_attendees = last_event.findAll(\"div\", attrs={\"height\": 30})\n", "venue = venue_and_attendees[0].text\n", "num_attendees = int(venue_and_attendees[-1].text)"]}, {"cell_type": "code", "execution_count": 32, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Name: UnterMania II\n", "Venue: TBA - New York\n", "Date: Sat, 30 Mar\n", "Number of attendees: 457\n"]}], "source": ["\n", "# Ok, that crashes because there is no attendee count. Let's\n", "# put a try/except and set the attendee count to NaN, since\n", "# that represents \"missing data\" reasonably\n", "\n", "try:\n", "    num_attendees = int(venue_and_attendees[-1].text)\n", "except ValueError:\n", "    num_attendees = np.nan\n", "    \n", "print(\"Name:\", name)\n", "print(\"Venue:\", venue)\n", "print(\"Date:\", date)\n", "print(\"Number of attendees:\", num_attendees)\n", "\n", "# Now we have code that should work for events with and\n", "# without attendee counts"]}, {"cell_type": "code", "execution_count": 33, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>0</th>\n", "      <th>1</th>\n", "      <th>2</th>\n", "      <th>3</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>UnterMania II</td>\n", "      <td>TBA - New York</td>\n", "      <td>Sat, 30 Mar</td>\n", "      <td>457.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>Cocoon New York: Sven V\u00e4th, Ilario Alicante, B...</td>\n", "      <td>99 Scott Ave</td>\n", "      <td>Sat, 30 Mar</td>\n", "      <td>407.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>Horse Meat Disco - New York Residency</td>\n", "      <td>Elsewhere</td>\n", "      <td>Sat, 30 Mar</td>\n", "      <td>375.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>Rave: Underground Resistance All Night</td>\n", "      <td>Nowadays</td>\n", "      <td>Sat, 30 Mar</td>\n", "      <td>232.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>Believe You Me // Beta Librae, Stephan Kimbel,...</td>\n", "      <td>TBA - New York</td>\n", "      <td>Sat, 30 Mar</td>\n", "      <td>89.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>114</th>\n", "      <td>A Night at the Baths</td>\n", "      <td>C'mon Everybody</td>\n", "      <td>Fri, 5 Apr</td>\n", "      <td>1.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>115</th>\n", "      <td>Blaqk Audio</td>\n", "      <td>Music Hall of Williamsburg</td>\n", "      <td>Fri, 5 Apr</td>\n", "      <td>1.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>116</th>\n", "      <td>Erik the Lover</td>\n", "      <td>Erv's</td>\n", "      <td>Fri, 5 Apr</td>\n", "      <td>1.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>117</th>\n", "      <td>Wax On Vissions</td>\n", "      <td>Starliner</td>\n", "      <td>Fri, 5 Apr</td>\n", "      <td>1.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>118</th>\n", "      <td>Schimanski &amp; Good Looks present: Mercer</td>\n", "      <td>Schimanski</td>\n", "      <td>Fri, 5 Apr</td>\n", "      <td>1.0</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>119 rows \u00d7 4 columns</p>\n", "</div>"], "text/plain": ["                                                     0  \\\n", "0                                        UnterMania II   \n", "1    Cocoon New York: Sven V\u00e4th, Ilario Alicante, B...   \n", "2                Horse Meat Disco - New York Residency   \n", "3               Rave: Underground Resistance All Night   \n", "4    Believe You Me // Beta Librae, Stephan Kimbel,...   \n", "..                                                 ...   \n", "114                               A Night at the Baths   \n", "115                                        Blaqk Audio   \n", "116                                     Erik the Lover   \n", "117                                    Wax On Vissions   \n", "118            Schimanski & Good Looks present: Mercer   \n", "\n", "                              1            2      3  \n", "0                TBA - New York  Sat, 30 Mar  457.0  \n", "1                  99 Scott Ave  Sat, 30 Mar  407.0  \n", "2                     Elsewhere  Sat, 30 Mar  375.0  \n", "3                      Nowadays  Sat, 30 Mar  232.0  \n", "4                TBA - New York  Sat, 30 Mar   89.0  \n", "..                          ...          ...    ...  \n", "114             C'mon Everybody   Fri, 5 Apr    1.0  \n", "115  Music Hall of Williamsburg   Fri, 5 Apr    1.0  \n", "116                       Erv's   Fri, 5 Apr    1.0  \n", "117                   Starliner   Fri, 5 Apr    1.0  \n", "118                  Schimanski   Fri, 5 Apr    1.0  \n", "\n", "[119 rows x 4 columns]"]}, "execution_count": 33, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# Loop over all of the event entries, extract this information\n", "# from each, and assemble a dataframe\n", "\n", "# Create an empty list to hold results\n", "rows = []\n", "\n", "# Loop over all date containers on the page\n", "for date_container in dates:\n", "    \n", "    # First check if this is one of the empty divs. If it is,\n", "    # skip ahead to the next one\n", "    if not date_container.text:\n", "        continue\n", "    \n", "    # Same logic as above to extract the date\n", "    date = date_container.find(\"div\", class_=\"sticky-header\").text\n", "    date = date.strip(\"'\u0338\")\n", "    \n", "    # This time, loop over all of the events\n", "    events = date_container.findChildren(\"ul\")\n", "    for event in events:\n", "        \n", "        # Same logic as above to extract the name, venue, attendees\n", "        name = event.find(\"h3\").text\n", "        venue_and_attendees = event.findAll(\"div\", attrs={\"height\": 30})\n", "        venue = venue_and_attendees[0].text\n", "        try:\n", "            num_attendees = int(venue_and_attendees[-1].text)\n", "        except ValueError:\n", "            num_attendees = np.nan\n", "            \n", "        # New piece here: appending the new information to rows list\n", "        rows.append([name, venue, date, num_attendees])\n", "\n", "# Make the list of lists into a dataframe and display\n", "df = pd.DataFrame(rows)\n", "df"]}, {"cell_type": "code", "execution_count": 34, "metadata": {}, "outputs": [], "source": ["\n", "# Bring it all together in a function that makes the request, gets the\n", "# list of entries from the response, loops over that list to extract the\n", "# name, venue, date, and number of attendees for each event, and returns\n", "# that list of events as a dataframe\n", "\n", "def scrape_events(events_page_url):\n", "    # Make the request and parse the response as HTML\n", "    response = requests.get(events_page_url)\n", "    soup = BeautifulSoup(response.content, \"html.parser\")\n", "    \n", "    # Find the container with the relevant content\n", "    events_all_div = soup.find('div', attrs={\"data-tracking-id\": \"events-all\"})\n", "    event_listings = events_all_div.find(\"ul\").find(\"li\")\n", "    dates = event_listings.findChildren(recursive=False)\n", "    \n", "    # Loop over all dates, an all events on each date, and\n", "    # add them to the list\n", "    rows = []\n", "    for date_container in dates:\n", "        \n", "        if not date_container.text:\n", "            continue\n", "\n", "        date = date_container.find(\"div\", class_=\"sticky-header\").text\n", "        date = date.strip(\"'\u0338\")\n", "\n", "        events = date_container.findChildren(\"ul\")\n", "        for event in events:\n", "            \n", "            name = event.find(\"h3\").text\n", "            venue_and_attendees = event.findAll(\"div\", attrs={\"height\": 30})\n", "            venue = venue_and_attendees[0].text\n", "            try:\n", "                num_attendees = int(venue_and_attendees[-1].text)\n", "            except ValueError:\n", "                num_attendees = np.nan\n", "\n", "            rows.append([name, venue, date, num_attendees])\n", "\n", "    df = pd.DataFrame(rows)\n", "    # This time also specify the column names\n", "    df.columns = [\"Event_Name\", \"Venue\", \"Event_Date\", \"Number_of_Attendees\"]\n", "    return df"]}, {"cell_type": "code", "execution_count": 35, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>Event_Name</th>\n", "      <th>Venue</th>\n", "      <th>Event_Date</th>\n", "      <th>Number_of_Attendees</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>UnterMania II</td>\n", "      <td>TBA - New York</td>\n", "      <td>Sat, 30 Mar</td>\n", "      <td>457.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>Cocoon New York: Sven V\u00e4th, Ilario Alicante, B...</td>\n", "      <td>99 Scott Ave</td>\n", "      <td>Sat, 30 Mar</td>\n", "      <td>407.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>Horse Meat Disco - New York Residency</td>\n", "      <td>Elsewhere</td>\n", "      <td>Sat, 30 Mar</td>\n", "      <td>375.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>Rave: Underground Resistance All Night</td>\n", "      <td>Nowadays</td>\n", "      <td>Sat, 30 Mar</td>\n", "      <td>232.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>Believe You Me // Beta Librae, Stephan Kimbel,...</td>\n", "      <td>TBA - New York</td>\n", "      <td>Sat, 30 Mar</td>\n", "      <td>89.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>114</th>\n", "      <td>A Night at the Baths</td>\n", "      <td>C'mon Everybody</td>\n", "      <td>Fri, 5 Apr</td>\n", "      <td>1.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>115</th>\n", "      <td>Blaqk Audio</td>\n", "      <td>Music Hall of Williamsburg</td>\n", "      <td>Fri, 5 Apr</td>\n", "      <td>1.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>116</th>\n", "      <td>Erik the Lover</td>\n", "      <td>Erv's</td>\n", "      <td>Fri, 5 Apr</td>\n", "      <td>1.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>117</th>\n", "      <td>Wax On Vissions</td>\n", "      <td>Starliner</td>\n", "      <td>Fri, 5 Apr</td>\n", "      <td>1.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>118</th>\n", "      <td>Schimanski &amp; Good Looks present: Mercer</td>\n", "      <td>Schimanski</td>\n", "      <td>Fri, 5 Apr</td>\n", "      <td>1.0</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>119 rows \u00d7 4 columns</p>\n", "</div>"], "text/plain": ["                                            Event_Name  \\\n", "0                                        UnterMania II   \n", "1    Cocoon New York: Sven V\u00e4th, Ilario Alicante, B...   \n", "2                Horse Meat Disco - New York Residency   \n", "3               Rave: Underground Resistance All Night   \n", "4    Believe You Me // Beta Librae, Stephan Kimbel,...   \n", "..                                                 ...   \n", "114                               A Night at the Baths   \n", "115                                        Blaqk Audio   \n", "116                                     Erik the Lover   \n", "117                                    Wax On Vissions   \n", "118            Schimanski & Good Looks present: Mercer   \n", "\n", "                          Venue   Event_Date  Number_of_Attendees  \n", "0                TBA - New York  Sat, 30 Mar                457.0  \n", "1                  99 Scott Ave  Sat, 30 Mar                407.0  \n", "2                     Elsewhere  Sat, 30 Mar                375.0  \n", "3                      Nowadays  Sat, 30 Mar                232.0  \n", "4                TBA - New York  Sat, 30 Mar                 89.0  \n", "..                          ...          ...                  ...  \n", "114             C'mon Everybody   Fri, 5 Apr                  1.0  \n", "115  Music Hall of Williamsburg   Fri, 5 Apr                  1.0  \n", "116                       Erv's   Fri, 5 Apr                  1.0  \n", "117                   Starliner   Fri, 5 Apr                  1.0  \n", "118                  Schimanski   Fri, 5 Apr                  1.0  \n", "\n", "[119 rows x 4 columns]"]}, "execution_count": 35, "metadata": {}, "output_type": "execute_result"}], "source": ["scrape_events(EVENTS_PAGE_URL)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Write a Function to Retrieve the URL for the Next Page\n", "\n", "As you scroll down, there should be a button labeled \"Next Week\" that will take you to the next page of events. Write code to find that button and extract the URL from it.\n", "\n", "This is a relative path, so make sure you add `https://web.archive.org` to the front to get the URL.\n", "\n", "![next page](images/ra_next.png)"]}, {"cell_type": "code", "execution_count": 36, "metadata": {}, "outputs": [{"data": {"text/plain": ["'https://web.archive.org/web/20210326225933/https://ra.co/events/us/newyork?week=2019-04-06'"]}, "execution_count": 36, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# Find the link, find the relative path, create the URL for the current `soup`\n", "\n", "# This is tricky again, since there are not a lot of\n", "# human-readable CSS classes\n", "\n", "# One unique thing we notice is a > icon on the part where\n", "# you click to go to the next page. It's an SVG with an \n", "# aria-label of \"Right arrow\"\n", "svg = soup.find(\"svg\", attrs={\"aria-label\": \"Right arrow\"})\n", "\n", "# That SVG is inside of a div\n", "svg_parent = svg.parent\n", "\n", "# And the tag right before that div (its \"previous sibling\")\n", "# is an anchor (link) tag with the path we need\n", "link = svg.parent.previousSibling\n", "\n", "# Then we can extract the path from that link to build the full URL\n", "relative_path = link.get(\"href\")\n", "next_page_url = \"https://web.archive.org\" + relative_path\n", "next_page_url"]}, {"cell_type": "code", "execution_count": 37, "metadata": {}, "outputs": [], "source": ["\n", "# Fill in this function, to take in the current page's URL and return the\n", "# next page's URL\n", "def next_page(url):\n", "    # Get the content\n", "    response = requests.get(url)\n", "    soup = BeautifulSoup(response.content, \"html.parser\")\n", "    \n", "    # Extract the relative path to build the full URL\n", "    svg = soup.find(\"svg\", attrs={\"aria-label\": \"Right arrow\"})\n", "    svg_parent = svg.parent\n", "    link = svg.parent.previousSibling\n", "    relative_path = link.get(\"href\")\n", "    next_page_url = \"https://web.archive.org\" + relative_path\n", "    return next_page_url"]}, {"cell_type": "code", "execution_count": 38, "metadata": {}, "outputs": [{"data": {"text/plain": ["'https://web.archive.org/web/20210326225933/https://ra.co/events/us/newyork?week=2019-04-06'"]}, "execution_count": 38, "metadata": {}, "output_type": "execute_result"}], "source": ["next_page(EVENTS_PAGE_URL)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Scrape the Next 500 Events\n", "\n", "In other words, repeatedly call `scrape_events` and `next_page` until you have assembled a dataframe with at least 500 rows.\n", "\n", "Display the data sorted by the number of attendees, greatest to least.\n", "\n", "We recommend adding a brief `time.sleep` call between `requests.get` calls to avoid rate limiting."]}, {"cell_type": "code", "execution_count": 39, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>Event_Name</th>\n", "      <th>Venue</th>\n", "      <th>Event_Date</th>\n", "      <th>Number_of_Attendees</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>UnterMania II</td>\n", "      <td>TBA - New York</td>\n", "      <td>Sat, 30 Mar</td>\n", "      <td>457.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>Cocoon New York: Sven V\u00e4th, Ilario Alicante, B...</td>\n", "      <td>99 Scott Ave</td>\n", "      <td>Sat, 30 Mar</td>\n", "      <td>407.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>Horse Meat Disco - New York Residency</td>\n", "      <td>Elsewhere</td>\n", "      <td>Sat, 30 Mar</td>\n", "      <td>375.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>Rave: Underground Resistance All Night</td>\n", "      <td>Nowadays</td>\n", "      <td>Sat, 30 Mar</td>\n", "      <td>232.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>Believe You Me // Beta Librae, Stephan Kimbel,...</td>\n", "      <td>TBA - New York</td>\n", "      <td>Sat, 30 Mar</td>\n", "      <td>89.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>119</th>\n", "      <td>Sleepy &amp; Boo, Unseen., Dysco, Joeoh</td>\n", "      <td>Rose Gold</td>\n", "      <td>Fri, 3 May</td>\n", "      <td>2.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>120</th>\n", "      <td>Diving for Disco with Jake From Extra Water</td>\n", "      <td>Our Wicked Lady</td>\n", "      <td>Fri, 3 May</td>\n", "      <td>2.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>121</th>\n", "      <td>The Happy Hour After Work Party at Doha Nightclub</td>\n", "      <td>Doha Club</td>\n", "      <td>Fri, 3 May</td>\n", "      <td>1.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>122</th>\n", "      <td>Best of the Boogie</td>\n", "      <td>Erv's</td>\n", "      <td>Fri, 3 May</td>\n", "      <td>1.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>123</th>\n", "      <td>[CANCELLED] Sound New York Pres Schuld, Sven M...</td>\n", "      <td>30 Wall St</td>\n", "      <td>Fri, 3 May</td>\n", "      <td>145.0</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>606 rows \u00d7 4 columns</p>\n", "</div>"], "text/plain": ["                                            Event_Name            Venue  \\\n", "0                                        UnterMania II   TBA - New York   \n", "1    Cocoon New York: Sven V\u00e4th, Ilario Alicante, B...     99 Scott Ave   \n", "2                Horse Meat Disco - New York Residency        Elsewhere   \n", "3               Rave: Underground Resistance All Night         Nowadays   \n", "4    Believe You Me // Beta Librae, Stephan Kimbel,...   TBA - New York   \n", "..                                                 ...              ...   \n", "119                Sleepy & Boo, Unseen., Dysco, Joeoh        Rose Gold   \n", "120        Diving for Disco with Jake From Extra Water  Our Wicked Lady   \n", "121  The Happy Hour After Work Party at Doha Nightclub        Doha Club   \n", "122                                 Best of the Boogie            Erv's   \n", "123  [CANCELLED] Sound New York Pres Schuld, Sven M...       30 Wall St   \n", "\n", "      Event_Date  Number_of_Attendees  \n", "0    Sat, 30 Mar                457.0  \n", "1    Sat, 30 Mar                407.0  \n", "2    Sat, 30 Mar                375.0  \n", "3    Sat, 30 Mar                232.0  \n", "4    Sat, 30 Mar                 89.0  \n", "..           ...                  ...  \n", "119   Fri, 3 May                  2.0  \n", "120   Fri, 3 May                  2.0  \n", "121   Fri, 3 May                  1.0  \n", "122   Fri, 3 May                  1.0  \n", "123   Fri, 3 May                145.0  \n", "\n", "[606 rows x 4 columns]"]}, "execution_count": 39, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# Make a dataframe to store results. We will concatenate\n", "# additional dfs as they are returned\n", "overall_df = pd.DataFrame()\n", "\n", "current_url = EVENTS_PAGE_URL\n", "while overall_df.shape[0] <= 500:\n", "    # Get all events from the current URL\n", "    df = scrape_events(current_url)\n", "    time.sleep(.2)\n", "    # Add the data to the overall df\n", "    overall_df = pd.concat([overall_df, df])\n", "    # Get the next URL and set it as the current URL\n", "    current_url = next_page(current_url)\n", "    time.sleep(.2)\n", "\n", "overall_df"]}, {"cell_type": "code", "execution_count": 40, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>Event_Name</th>\n", "      <th>Venue</th>\n", "      <th>Event_Date</th>\n", "      <th>Number_of_Attendees</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>Zero presents... The Masquerade</td>\n", "      <td>The 1896</td>\n", "      <td>Sat, 6 Apr</td>\n", "      <td>919.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>65</th>\n", "      <td>Secret Solstice Pre-Party (Free Entry): Metro ...</td>\n", "      <td>Kings Hall - Avant Gardner</td>\n", "      <td>Thu, 18 Apr</td>\n", "      <td>670.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>Nina Kraviz / James Murphy / Justin Cudmore</td>\n", "      <td>Knockdown Center</td>\n", "      <td>Sat, 20 Apr</td>\n", "      <td>501.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>89</th>\n", "      <td>Stavroz live! presented by Zero</td>\n", "      <td>The Williamsburg Hotel</td>\n", "      <td>Fri, 12 Apr</td>\n", "      <td>481.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>91</th>\n", "      <td>Teksupport: Honey Dijon (All Night Long) Sold Out</td>\n", "      <td>99 Scott Ave</td>\n", "      <td>Fri, 5 Apr</td>\n", "      <td>463.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>56</th>\n", "      <td>420: A Musical Experience</td>\n", "      <td>The Kraine Theater</td>\n", "      <td>Mon, 22 Apr</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "    <tr>\n", "      <th>61</th>\n", "      <td>420: A Musical Experience</td>\n", "      <td>The Kraine Theater</td>\n", "      <td>Tue, 23 Apr</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "    <tr>\n", "      <th>75</th>\n", "      <td>420: A Musical Experience</td>\n", "      <td>The Kraine Theater</td>\n", "      <td>Wed, 24 Apr</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "    <tr>\n", "      <th>34</th>\n", "      <td>Klandestino Brunch with Electronic Music</td>\n", "      <td>Avena Downtown</td>\n", "      <td>Sat, 27 Apr</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "    <tr>\n", "      <th>48</th>\n", "      <td>Digital Clippings</td>\n", "      <td>Magick City</td>\n", "      <td>Sun, 28 Apr</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>606 rows \u00d7 4 columns</p>\n", "</div>"], "text/plain": ["                                           Event_Name  \\\n", "0                     Zero presents... The Masquerade   \n", "65  Secret Solstice Pre-Party (Free Entry): Metro ...   \n", "0         Nina Kraviz / James Murphy / Justin Cudmore   \n", "89                    Stavroz live! presented by Zero   \n", "91  Teksupport: Honey Dijon (All Night Long) Sold Out   \n", "..                                                ...   \n", "56                          420: A Musical Experience   \n", "61                          420: A Musical Experience   \n", "75                          420: A Musical Experience   \n", "34           Klandestino Brunch with Electronic Music   \n", "48                                  Digital Clippings   \n", "\n", "                         Venue   Event_Date  Number_of_Attendees  \n", "0                     The 1896   Sat, 6 Apr                919.0  \n", "65  Kings Hall - Avant Gardner  Thu, 18 Apr                670.0  \n", "0             Knockdown Center  Sat, 20 Apr                501.0  \n", "89      The Williamsburg Hotel  Fri, 12 Apr                481.0  \n", "91                99 Scott Ave   Fri, 5 Apr                463.0  \n", "..                         ...          ...                  ...  \n", "56          The Kraine Theater  Mon, 22 Apr                  NaN  \n", "61          The Kraine Theater  Tue, 23 Apr                  NaN  \n", "75          The Kraine Theater  Wed, 24 Apr                  NaN  \n", "34              Avena Downtown  Sat, 27 Apr                  NaN  \n", "48                 Magick City  Sun, 28 Apr                  NaN  \n", "\n", "[606 rows x 4 columns]"]}, "execution_count": 40, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "# Display in the specified sorted order\n", "overall_df.sort_values(\"Number_of_Attendees\", ascending=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Summary \n", "\n", "Congratulations! In this lab, you successfully developed a pipeline to scrape a website for concert event information!"]}], "metadata": {"kernelspec": {"display_name": "Python (learn-env)", "language": "python", "name": "learn-env"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 2}